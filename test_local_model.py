#!/usr/bin/env python3
"""
æµ‹è¯•æœ¬åœ°æ¨¡å‹é…ç½®æ˜¯å¦å¯ç”¨
"""
import asyncio
from droidrun.config import get_config_manager
from droidrun.agent.utils.llm_picker import load_llm
from llama_index.core.base.llms.types import ChatMessage


async def test_model():
    """æµ‹è¯•æ¨¡å‹é…ç½®å’Œè¿æ¥"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•æœ¬åœ°æ¨¡å‹é…ç½®")
    print("=" * 60)
    
    # 1. éªŒè¯é…ç½®åŠ è½½
    print("\nğŸ“‹ æ­¥éª¤ 1: éªŒè¯é…ç½®æ–‡ä»¶åŠ è½½")
    try:
        config_manager = get_config_manager()
        api_config = config_manager.get_api_config()
        
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ:")
        print(f"  - Model: {api_config.model}")
        print(f"  - API Base: {api_config.api_base}")
        print(f"  - API Key: {'***' if api_config.api_key else 'None'}")
        print(f"  - Timeout: {api_config.timeout}s")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. åˆ›å»º LLM å®ä¾‹
    print("\nğŸ¤– æ­¥éª¤ 2: åˆ›å»º LLM å®ä¾‹")
    try:
        llm = load_llm(
            provider_name="OpenAILike",
            model=api_config.model,
            api_base=api_config.api_base,
            api_key=api_config.api_key or "dummy-key",
            is_chat_model=True,
            timeout=api_config.timeout,
        )
        print("âœ… LLM å®ä¾‹åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ LLM å®ä¾‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 3. æµ‹è¯•æ¨¡å‹å“åº”
    print("\nğŸ’¬ æ­¥éª¤ 3: æµ‹è¯•æ¨¡å‹å“åº”")
    try:
        test_message = ChatMessage(
            role="user",
            content="ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        )
        
        print("  å‘é€æµ‹è¯•æ¶ˆæ¯: 'ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚'")
        print("  ç­‰å¾…æ¨¡å‹å“åº”...")
        
        response = await llm.achat([test_message])
        
        print(f"âœ… æ¨¡å‹å“åº”æˆåŠŸ:")
        print(f"  å“åº”å†…å®¹: {response.message.content}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å“åº”å¤±è´¥: {e}")
        print(f"\nğŸ’¡ å¯èƒ½çš„åŸå› :")
        print(f"  1. æ¨¡å‹æœåŠ¡æœªå¯åŠ¨")
        print(f"  2. API åœ°å€é…ç½®é”™è¯¯")
        print(f"  3. æ¨¡å‹åç§°ä¸åŒ¹é…")
        print(f"  4. ç½‘ç»œè¿æ¥é—®é¢˜")
        return False
    
    # 4. å®Œæ•´æ€§æµ‹è¯•
    print("\nğŸ¯ æ­¥éª¤ 4: å®Œæ•´æ€§æµ‹è¯•")
    try:
        test_messages = [
            ChatMessage(role="user", content="1+1ç­‰äºå‡ ï¼Ÿç›´æ¥å›ç­”æ•°å­—ã€‚")
        ]
        
        print("  å‘é€æµ‹è¯•é—®é¢˜: '1+1ç­‰äºå‡ ï¼Ÿ'")
        response = await llm.achat(test_messages)
        
        print(f"âœ… å®Œæ•´æ€§æµ‹è¯•é€šè¿‡:")
        print(f"  å“åº”: {response.message.content}")
        
    except Exception as e:
        print(f"âš ï¸  å®Œæ•´æ€§æµ‹è¯•å‡ºç°é—®é¢˜: {e}")
        return False
    
    # æˆåŠŸ
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æœ¬åœ°æ¨¡å‹é…ç½®å¯ç”¨ï¼")
    print("=" * 60)
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  - å¯ä»¥ç›´æ¥è¿è¡Œ DroidRun ä»»åŠ¡")
    print("  - æ¨¡å‹å°†è‡ªåŠ¨ä½¿ç”¨ä½ é…ç½®çš„æœ¬åœ°æœåŠ¡")
    print()
    
    return True


if __name__ == "__main__":
    try:
        result = asyncio.run(test_model())
        exit(0 if result else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        exit(1)
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•å‡ºç°æœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
