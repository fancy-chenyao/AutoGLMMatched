"""
å¤±è´¥åæ€å™¨ - æ ¸å¿ƒåˆ†æå¼•æ“

è¯¥æ¨¡å—å®ç°äº†å¤±è´¥åœºæ™¯çš„è‡ªåŠ¨åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬ UI çŠ¶æ€å¯¹æ¯”ã€LLM é©±åŠ¨çš„åŸå› åˆ†æå’Œå»ºè®®ç”Ÿæˆã€‚
"""

import json
import logging
import hashlib
import time
from typing import Dict, Any, Optional, Tuple, List
from llama_index.core.base.llms.types import ChatMessage
from llama_index.core.llms.llm import LLM

from droidrun.agent.reflection.reflection_types import FailureContext, FailureReflection
from droidrun.agent.reflection.reflection_prompts import (
    HOT_START_FAILURE_SYSTEM_PROMPT,
    COLD_START_FAILURE_SYSTEM_PROMPT,
    build_hot_start_failure_user_message,
    build_cold_start_failure_user_message,
)
from droidrun.agent.utils.logging_utils import LoggingUtils

logger = logging.getLogger("droidrun")


class FailureReflector:
    """
    å¤±è´¥åˆ†æåæ€å™¨
    
    è¯¥ç±»è´Ÿè´£åˆ†æä»»åŠ¡æ‰§è¡Œå¤±è´¥çš„åŸå› ï¼Œå¹¶æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
    ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
    1. UI çŠ¶æ€å¯¹æ¯”åˆ†æ
    2. LLM é©±åŠ¨çš„å¤±è´¥åŸå› åˆ†æ
    3. å»ºè®®ç”Ÿæˆå’Œç½®ä¿¡åº¦è®¡ç®—
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        reflector = FailureReflector(llm=llm, tools_instance=tools, debug=True)
        context = FailureContext.from_hot_start_failure(...)
        reflection = await reflector.analyze_failure(context)
    """
    
    def __init__(
        self,
        llm: LLM,
        tools_instance: Any = None,
        debug: bool = False,
    ):
        """
        åˆå§‹åŒ–åæ€å™¨
        
        Args:
            llm: LLM å®ä¾‹ï¼Œç”¨äºç”Ÿæˆåæ€åˆ†æ
            tools_instance: Tools å®ä¾‹ï¼Œç”¨äº UI hash è®¡ç®—ï¼ˆå¯é€‰ï¼‰
            debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        """
        self.llm = llm
        self.tools_instance = tools_instance
        self.debug = debug
        self._init_prompts()
        
        # åæ€ç»“æœç¼“å­˜ï¼ˆä¼šè¯çº§åˆ«ï¼‰
        self._reflection_cache: Dict[str, FailureReflection] = {}
        
        LoggingUtils.log_info("FailureReflector", "âœ¨ Failure reflector initialized")
    
    def _init_prompts(self):
        """åˆå§‹åŒ–æç¤ºè¯"""
        self.hot_start_system_prompt = HOT_START_FAILURE_SYSTEM_PROMPT
        self.cold_start_system_prompt = COLD_START_FAILURE_SYSTEM_PROMPT
    
    async def analyze_failure(
        self, 
        context: FailureContext
    ) -> FailureReflection:
        """
        åˆ†æå¤±è´¥å¹¶ç”Ÿæˆåæ€
        
        è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼Œæ‰§è¡Œå®Œæ•´çš„å¤±è´¥åˆ†ææµç¨‹ã€‚
        
        Args:
            context: å¤±è´¥åœºæ™¯çš„å®Œæ•´ä¸Šä¸‹æ–‡
            
        Returns:
            FailureReflection: åŒ…å«é—®é¢˜è¯Šæ–­å’Œæ”¹è¿›å»ºè®®çš„åæ€ç»“æœ
            
        Raises:
            Exception: LLM è°ƒç”¨å¤±è´¥æˆ– JSON è§£æé”™è¯¯æ—¶
        """
        start_time = time.time()  # å¼€å§‹è®¡æ—¶
        
        LoggingUtils.log_info(
            "FailureReflector",
            "ğŸ” Analyzing failure: type={type}, step={step}",
            type=context.failure_type,
            step=context.error_step
        )
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_failure_cache_key(context)
        if cache_key in self._reflection_cache:
            elapsed = time.time() - start_time
            LoggingUtils.log_debug(
                "FailureReflector", 
                "âœ… Using cached reflection (time={time:.3f}s)",
                time=elapsed
            )
            return self._reflection_cache[cache_key]
        
        try:
            # 1. åˆ†æ UI å˜åŒ–ï¼ˆä¸éœ€è¦ LLMï¼‰
            ui_changed, ui_change_summary = self._analyze_ui_change(
                context.pre_ui_state, 
                context.post_ui_state
            )
            
            # 2. è°ƒç”¨ LLM è¿›è¡Œæ·±åº¦åˆ†æ
            reflection = await self._call_llm_for_analysis(
                context, 
                ui_changed, 
                ui_change_summary
            )
            
            # 3. å¢å¼ºåæ€ç»“æœï¼ˆåªåœ¨ LLM æœªæä¾›æ—¶è¡¥å……ï¼‰
            # æ³¨æ„ï¼šä¸è¦å¼ºåˆ¶è¦†ç›– LLM çš„åˆ¤æ–­ï¼Œå¦åˆ™ç½®ä¿¡åº¦è®¡ç®—ä¸­çš„ä¸€è‡´æ€§æ£€æŸ¥ä¼šå¤±æ•ˆ
            if reflection.ui_change_summary is None and ui_change_summary:
                reflection.ui_change_summary = ui_change_summary
            
            # 4. ç¼“å­˜ç»“æœ
            self._reflection_cache[cache_key] = reflection
            
            # è®°å½•æ€»è€—æ—¶
            elapsed = time.time() - start_time
            LoggingUtils.log_success(
                "FailureReflector",
                "âœ… Analysis complete: problem={problem}, confidence={conf:.2f}, time={time:.2f}s",
                problem=reflection.problem_type,
                conf=reflection.confidence,
                time=elapsed
            )
            
            return reflection
            
        except Exception as e:
            elapsed = time.time() - start_time
            LoggingUtils.log_error(
                "FailureReflector",
                "Failed to analyze failure after {time:.2f}s: {error}",
                time=elapsed,
                error=str(e)
            )
            if self.debug:
                import traceback
                LoggingUtils.log_error("FailureReflector", "{trace}", trace=traceback.format_exc())
            
            # è¿”å›ä¿å®ˆçš„å›é€€ç­–ç•¥
            return self._create_fallback_reflection(context)
    
    def _analyze_ui_change(
        self, 
        pre_ui: Optional[Dict[str, Any]], 
        post_ui: Optional[Dict[str, Any]]
    ) -> Tuple[bool, Optional[str]]:
        """
        å¯¹æ¯”æ‰§è¡Œå‰åçš„ UI çŠ¶æ€
        
        Args:
            pre_ui: æ‰§è¡Œå‰çš„ UI çŠ¶æ€
            post_ui: æ‰§è¡Œåçš„ UI çŠ¶æ€
            
        Returns:
            (ui_changed, ui_change_summary): æ˜¯å¦å˜åŒ–å’Œå˜åŒ–æè¿°
        """
        if not pre_ui or not post_ui:
            return False, None
        
        try:
            # 1. å¯¹æ¯”å…ƒç´ æ•°é‡
            pre_elements = pre_ui.get('a11y_tree', [])
            post_elements = post_ui.get('a11y_tree', [])
            
            pre_count = len(pre_elements)
            post_count = len(post_elements)
            
            if pre_count != post_count:
                change_desc = f"å…ƒç´ æ•°é‡ä» {pre_count} å˜ä¸º {post_count}"
                if post_count > pre_count:
                    change_desc += f"ï¼ˆæ–°å¢äº† {post_count - pre_count} ä¸ªå…ƒç´ ï¼‰"
                else:
                    change_desc += f"ï¼ˆå‡å°‘äº† {pre_count - post_count} ä¸ªå…ƒç´ ï¼‰"
                return True, change_desc
            
            # 2. å¯¹æ¯” UI hashï¼ˆä½¿ç”¨å¢å¼ºçš„ hash è®¡ç®—ï¼‰
            pre_hash = self._calculate_enhanced_ui_hash(pre_ui)
            post_hash = self._calculate_enhanced_ui_hash(post_ui)
            
            if pre_hash != post_hash:
                # 3. è¯¦ç»†åˆ†æå˜åŒ–å†…å®¹
                diff_summary = self._analyze_ui_differences(pre_elements, post_elements)
                return True, diff_summary
            
            return False, None
            
        except Exception as e:
            LoggingUtils.log_warning(
                "FailureReflector",
                "Failed to analyze UI change: {error}",
                error=str(e)
            )
            return False, None
    
    def _calculate_enhanced_ui_hash(self, ui_state: Dict[str, Any]) -> str:
        """
        è®¡ç®— UI çŠ¶æ€çš„å¢å¼º hashï¼ˆå€Ÿé‰´ UIStabilityChecker çš„å®ç°ï¼‰
        
        Args:
            ui_state: UI çŠ¶æ€å­—å…¸
            
        Returns:
            hash å­—ç¬¦ä¸²
        """
        try:
            a11y_tree = ui_state.get('a11y_tree', [])
            if not a11y_tree:
                return ""
            
            # æå–å…³é”®ä¿¡æ¯ï¼šå‰ 50 ä¸ªå…ƒç´ çš„è¯¦ç»†ä¿¡æ¯
            elements_info = []
            for elem in a11y_tree[:50]:
                elem_info = (
                    elem.get('className', ''),
                    elem.get('text', ''),
                    elem.get('resourceId', ''),
                    elem.get('clickable', False),
                )
                elements_info.append(elem_info)
            
            return str(hash(str(elements_info)))
        except Exception as e:
            LoggingUtils.log_warning("FailureReflector", "Hash calculation failed: {error}", error=str(e))
            return ""
    
    def _analyze_ui_differences(
        self, 
        pre_elements: List[Dict[str, Any]], 
        post_elements: List[Dict[str, Any]]
    ) -> str:
        """
        è¯¦ç»†åˆ†æ UI å…ƒç´ çš„å˜åŒ–
        
        Args:
            pre_elements: æ‰§è¡Œå‰çš„å…ƒç´ åˆ—è¡¨
            post_elements: æ‰§è¡Œåçš„å…ƒç´ åˆ—è¡¨
            
        Returns:
            äººç±»å¯è¯»çš„å˜åŒ–æè¿°
        """
        try:
            changes = []
            
            # å¯¹æ¯”å‰ 10 ä¸ªå…ƒç´ çš„æ–‡æœ¬å˜åŒ–
            check_count = min(10, len(pre_elements), len(post_elements))
            for i in range(check_count):
                pre_text = pre_elements[i].get('text', '')
                post_text = post_elements[i].get('text', '')
                
                if pre_text != post_text:
                    if pre_text and post_text:
                        changes.append(f"ç´¢å¼• {i} çš„æ–‡æœ¬ä» '{pre_text}' å˜ä¸º '{post_text}'")
                    elif not pre_text and post_text:
                        changes.append(f"ç´¢å¼• {i} æ–°å¢æ–‡æœ¬ '{post_text}'")
                    elif pre_text and not post_text:
                        changes.append(f"ç´¢å¼• {i} çš„æ–‡æœ¬ '{pre_text}' è¢«ç§»é™¤")
            
            if changes:
                return "UI å…ƒç´ å‘ç”Ÿå˜åŒ–: " + "; ".join(changes[:3])  # æœ€å¤šæ˜¾ç¤º 3 ä¸ªå˜åŒ–
            else:
                return "UI å¸ƒå±€æˆ–å…ƒç´ å±æ€§å‘ç”Ÿäº†å˜åŒ–"
                
        except Exception as e:
            LoggingUtils.log_warning("FailureReflector", "UI diff analysis failed: {error}", error=str(e))
            return "UI å‘ç”Ÿäº†å˜åŒ–"
    
    async def _call_llm_for_analysis(
        self,
        context: FailureContext,
        ui_changed: bool,
        ui_change_summary: Optional[str],
    ) -> FailureReflection:
        """
        è°ƒç”¨ LLM è¿›è¡Œå¤±è´¥åˆ†æ
        
        Args:
            context: å¤±è´¥ä¸Šä¸‹æ–‡
            ui_changed: UI æ˜¯å¦å˜åŒ–
            ui_change_summary: UI å˜åŒ–æè¿°
            
        Returns:
            FailureReflection: åæ€ç»“æœ
        """
        try:
            # 1. å‡†å¤‡ç³»ç»Ÿæç¤ºè¯
            system_prompt = (
                HOT_START_FAILURE_SYSTEM_PROMPT 
                if context.failure_type == "hot_start" 
                else COLD_START_FAILURE_SYSTEM_PROMPT
            )
            
            # 2. æ„å»ºç”¨æˆ·æ¶ˆæ¯
            if context.failure_type == "hot_start":
                # å‡†å¤‡æ•°æ®
                pre_count = len(context.pre_ui_state.get('a11y_tree', [])) if context.pre_ui_state else 0
                post_count = len(context.post_ui_state.get('a11y_tree', [])) if context.post_ui_state else 0
                
                # æ ¼å¼åŒ–æœ€è¿‘åŠ¨ä½œ
                recent_actions_str = ""
                if context.recent_actions:
                    recent_actions_str = "\n".join([
                        f"{i+1}. {action.get('action', 'unknown')}({action.get('params', {})})"
                        for i, action in enumerate(context.recent_actions[-5:])  # æœ€è¿‘ 5 ä¸ª
                    ])
                
                user_message = build_hot_start_failure_user_message(
                    goal=context.goal,
                    failed_action=str(context.failed_action),
                    error_message=context.error_message,
                    error_step=context.error_step,
                    ui_changed=ui_changed,
                    ui_change_summary=ui_change_summary or "æ— æ˜æ˜¾å˜åŒ–",
                    expected_action=str(context.expected_action) if context.expected_action else None,
                    pre_ui_elements_count=pre_count,
                    post_ui_elements_count=post_count,
                    recent_actions=recent_actions_str,
                )
            else:
                user_message = build_cold_start_failure_user_message(
                    goal=context.goal,
                    failed_action=str(context.failed_action),
                    error_message=context.error_message,
                    current_step_description=context.current_step_description or "å½“å‰æ­¥éª¤",
                    ui_changed=ui_changed,
                    ui_change_summary=ui_change_summary,
                )
            
            # 3. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                ChatMessage(role="system", content=system_prompt),
                ChatMessage(role="user", content=user_message),
            ]
            
            LoggingUtils.log_debug(
                "FailureReflector",
                "ğŸ¤– Calling LLM for failure analysis..."
            )
            
            # 4. è°ƒç”¨ LLM
            response = await self.llm.achat(messages=messages)
            
            LoggingUtils.log_debug(
                "FailureReflector",
                "âœ… LLM response received: {length} chars",
                length=len(response.message.content)
            )
            
            # 5. è§£æ JSON å“åº”
            reflection = self._parse_llm_response(response.message.content)
            
            # 6. è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
            reflection.confidence = self._calculate_confidence(reflection, context, ui_changed)
            
            return reflection
            
        except Exception as e:
            LoggingUtils.log_error(
                "FailureReflector",
                "LLM analysis failed: {error}",
                error=str(e)
            )
            if self.debug:
                import traceback
                LoggingUtils.log_error("FailureReflector", "{trace}", trace=traceback.format_exc())
            
            # è¿”å›å›é€€åæ€
            return self._create_fallback_reflection(context)
    
    def _parse_llm_response(self, response_content: str) -> FailureReflection:
        """
        è§£æ LLM çš„ JSON å“åº”
        
        Args:
            response_content: LLM è¿”å›çš„æ–‡æœ¬å†…å®¹
            
        Returns:
            FailureReflection: è§£æåçš„åæ€ç»“æœ
            
        Raises:
            json.JSONDecodeError: JSON è§£æå¤±è´¥
        """
        try:
            # æ¸…ç†å“åº”å†…å®¹
            content = response_content.strip()
            
            # ç§»é™¤ markdown ä»£ç å—æ ¼å¼
            if content.startswith('```json'):
                content = content[7:]
            elif content.startswith('```'):
                content = content[3:]
            
            if content.endswith('```'):
                content = content[:-3]
            
            content = content.strip()
            
            # è§£æ JSON
            data = json.loads(content)
            
            # åˆ›å»º FailureReflection å¯¹è±¡
            reflection = FailureReflection.from_dict(data)
            
            LoggingUtils.log_debug(
                "FailureReflector",
                "âœ… Successfully parsed LLM response: {type}",
                type=reflection.problem_type
            )
            
            return reflection
            
        except json.JSONDecodeError as e:
            LoggingUtils.log_error(
                "FailureReflector",
                "Failed to parse JSON response: {error}",
                error=str(e)
            )
            LoggingUtils.log_error(
                "FailureReflector",
                "Raw response: {content}",
                content=response_content[:200]
            )
            raise
    
    def _calculate_confidence(
        self, 
        reflection: FailureReflection, 
        context: FailureContext,
        ui_changed: bool
    ) -> float:
        """
        è®¡ç®—åæ€å»ºè®®çš„ç½®ä¿¡åº¦
        
        Args:
            reflection: åˆæ­¥çš„åæ€ç»“æœ
            context: å¤±è´¥ä¸Šä¸‹æ–‡
            ui_changed: UI æ˜¯å¦å˜åŒ–
            
        Returns:
            ç½®ä¿¡åº¦å€¼ï¼ˆ0.0-1.0ï¼‰
        """
        # åŸºç¡€ç½®ä¿¡åº¦ï¼ˆæ¥è‡ª LLMï¼‰
        base_confidence = reflection.confidence
        
        # è°ƒæ•´å› å­
        adjustments = []
        
        # 1. UI å˜åŒ–æ£€æµ‹ä¸€è‡´æ€§
        if reflection.ui_changed == ui_changed:
            adjustments.append(0.1)  # ä¸€è‡´æ€§åŠ åˆ†
        else:
            adjustments.append(-0.1)  # ä¸ä¸€è‡´æ‰£åˆ†
        
        # 2. é”™è¯¯ä¿¡æ¯æ˜ç¡®æ€§
        if context.error_message and len(context.error_message) > 10:
            adjustments.append(0.05)  # æœ‰æ˜ç¡®é”™è¯¯ä¿¡æ¯
        
        # 3. å»ºè®®çš„å…·ä½“æ€§
        if reflection.specific_advice and len(reflection.specific_advice) > 20:
            adjustments.append(0.05)  # å»ºè®®è¶³å¤Ÿå…·ä½“
        
        # 4. çƒ­å¯åŠ¨åœºæ™¯ï¼šæœ‰é¢„æœŸåŠ¨ä½œå¯¹æ¯”
        if context.failure_type == "hot_start" and context.expected_action:
            adjustments.append(0.1)  # æœ‰æ›´å¤šä¿¡æ¯
        
        # 5. æœ‰å»ºè®®çš„æ›¿ä»£åŠ¨ä½œ
        if reflection.suggested_action or reflection.suggested_params:
            adjustments.append(0.05)  # æä¾›äº†å¯æ‰§è¡Œçš„å»ºè®®
        
        # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
        final_confidence = base_confidence + sum(adjustments)
        
        # é™åˆ¶åœ¨ 0.0-1.0 èŒƒå›´å†…
        final_confidence = max(0.0, min(1.0, final_confidence))
        
        LoggingUtils.log_debug(
            "FailureReflector",
            "Confidence: base={base:.2f}, adjustments={adj}, final={final:.2f}",
            base=base_confidence,
            adj=adjustments,
            final=final_confidence
        )
        
        return final_confidence
    
    def _create_fallback_reflection(self, context: FailureContext) -> FailureReflection:
        """
        åˆ›å»ºå›é€€åæ€ç»“æœï¼ˆå½“åˆ†æå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            context: å¤±è´¥ä¸Šä¸‹æ–‡
            
        Returns:
            FailureReflection: ä¿å®ˆçš„å›é€€ç­–ç•¥
        """
        return FailureReflection(
            problem_type="unknown",
            root_cause=f"Failed to analyze: {context.error_message}",
            ui_changed=False,
            ui_change_summary=None,
            recommended_strategy="fallback_cold_start",
            specific_advice="æ— æ³•åˆ†æå…·ä½“åŸå› ï¼Œå»ºè®®å›é€€åˆ°å†·å¯åŠ¨",
            confidence=0.3,
        )
    
    def _get_failure_cache_key(self, context: FailureContext) -> str:
        """
        ç”Ÿæˆå¤±è´¥åœºæ™¯çš„ç¼“å­˜ key
        
        Args:
            context: å¤±è´¥ä¸Šä¸‹æ–‡
            
        Returns:
            ç¼“å­˜ key å­—ç¬¦ä¸²
        """
        return f"{context.goal}_{context.failure_type}_{context.error_message}_{context.error_step}"
    
    def clear_cache(self):
        """æ¸…ç©ºåæ€ç»“æœç¼“å­˜"""
        self._reflection_cache.clear()
        LoggingUtils.log_debug("FailureReflector", "Reflection cache cleared")
